#!/usr/bin/env python3
"""
Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…ØµØ­Ø­
ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«Ù„Ø§Ø« ÙˆØ§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø­Ø³Ù†Ø©
"""

import numpy as np
import matplotlib.pyplot as plt
import sys
import os
from datetime import datetime
import json

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from adaptive_equations import AdaptiveGSEEquation, AdaptationDirection
    from three_theories_core import ThreeTheoriesIntegrator
    from expert_explorer_system import GSEExpertSystem, GSEExplorerSystem, ExplorerMode
    print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
except ImportError as e:
    print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª: {e}")
    sys.exit(1)

def generate_comprehensive_prime_data(max_num=150):
    """ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©"""
    
    def is_prime(n):
        if n < 2:
            return False
        for i in range(2, int(n**0.5) + 1):
            if n % i == 0:
                return False
        return True
    
    numbers = list(range(2, max_num + 1))
    prime_indicators = [1 if is_prime(n) else 0 for n in numbers]
    primes_list = [n for n in numbers if is_prime(n)]
    
    return np.array(numbers), np.array(prime_indicators), np.array(primes_list)

class FinalEnhancedGSEModel:
    """Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…ØµØ­Ø­"""
    
    def __init__(self):
        self.adaptive_equation = None
        self.theories_integrator = ThreeTheoriesIntegrator()
        self.expert_system = GSEExpertSystem()
        self.explorer_system = GSEExplorerSystem()
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø­Ø³Ù†Ø©
        self.optimal_threshold = 0.3
        self.training_history = []
        self.performance_metrics = {}
        
        print("ğŸš€ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
    
    def create_optimized_model(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ø³Ù† Ø¨Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù…Ø«Ù„Ù‰"""
        
        print("\nğŸ”§ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù…Ø­Ø³Ù†Ø©...")
        
        self.adaptive_equation = AdaptiveGSEEquation()
        
        # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù…Ø­Ø³Ù†Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¬Ø§Ø±Ø¨ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
        self.adaptive_equation.add_sigmoid_component(alpha=2.5, k=1.2, x0=8.0)    # Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµØºÙŠØ±Ø©
        self.adaptive_equation.add_sigmoid_component(alpha=2.0, k=1.0, x0=25.0)   # Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªÙˆØ³Ø·Ø©
        self.adaptive_equation.add_sigmoid_component(alpha=1.5, k=0.8, x0=50.0)   # Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
        self.adaptive_equation.add_sigmoid_component(alpha=1.0, k=0.6, x0=80.0)   # Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙƒØ¨Ø±
        self.adaptive_equation.add_linear_component(beta=0.005, gamma=0.0)        # Ø§ØªØ¬Ø§Ù‡ Ø¹Ø§Ù…
        
        print(f"   âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(self.adaptive_equation.components)} Ù…ÙƒÙˆÙ†Ø§Øª Ù…Ø­Ø³Ù†Ø©")
        print(f"   ğŸ“Š Ù…Ø¹Ø§Ù…Ù„Ø§Øª alpha: [2.5, 2.0, 1.5, 1.0]")
        print(f"   ğŸ“Š Ù…Ø¹Ø§Ù…Ù„Ø§Øª k: [1.2, 1.0, 0.8, 0.6]")
        
        return self.adaptive_equation
    
    def intelligent_training(self, x_data, y_data, max_iterations=8):
        """ØªØ¯Ø±ÙŠØ¨ Ø°ÙƒÙŠ Ù…ØªØ¯Ø±Ø¬"""
        
        print(f"\nğŸ¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªØ¯Ø±Ø¬...")
        
        if self.adaptive_equation is None:
            self.create_optimized_model()
        
        # Ù‚ÙŠØ§Ø³ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£ÙˆÙ„ÙŠ
        initial_error = self.adaptive_equation.calculate_error(x_data, y_data)
        print(f"   Ø®Ø·Ø£ Ø£ÙˆÙ„ÙŠ: {initial_error:.6f}")
        
        training_log = []
        
        # Ù…Ø±Ø­Ù„Ø© 1: ØªÙƒÙŠÙ Ø£Ø³Ø§Ø³ÙŠ
        print(f"\n   ğŸ”„ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„ØªÙƒÙŠÙ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ")
        for i in range(3):
            success = self.adaptive_equation.adapt_to_data(
                x_data, y_data, AdaptationDirection.IMPROVE_ACCURACY
            )
            current_error = self.adaptive_equation.calculate_error(x_data, y_data)
            improvement = initial_error - current_error if i == 0 else training_log[-1]['error'] - current_error
            
            training_log.append({
                'iteration': i + 1,
                'phase': 'basic_adaptation',
                'error': current_error,
                'improvement': improvement,
                'success': success
            })
            
            print(f"      ØªÙƒÙŠÙ {i+1}: Ø®Ø·Ø£ = {current_error:.6f}, ØªØ­Ø³Ù† = {improvement:.6f}")
            
            if not success:
                break
        
        # Ù…Ø±Ø­Ù„Ø© 2: ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«Ù„Ø§Ø«
        print(f"\n   ğŸ”¬ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«Ù„Ø§Ø«")
        pre_theories_error = self.adaptive_equation.calculate_error(x_data, y_data)
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø­Ø°Ø±
        self._apply_balanced_theories()
        
        post_theories_error = self.adaptive_equation.calculate_error(x_data, y_data)
        theories_improvement = pre_theories_error - post_theories_error
        
        training_log.append({
            'iteration': 'theories',
            'phase': 'three_theories',
            'error': post_theories_error,
            'improvement': theories_improvement,
            'success': theories_improvement > 0
        })
        
        print(f"      Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«Ù„Ø§Ø«: Ø®Ø·Ø£ = {post_theories_error:.6f}, ØªØ­Ø³Ù† = {theories_improvement:.6f}")
        
        # Ù…Ø±Ø­Ù„Ø© 3: ØªÙƒÙŠÙ Ù†Ù‡Ø§Ø¦ÙŠ
        print(f"\n   âš¡ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø§Ù„ØªÙƒÙŠÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
        for i in range(2):
            success = self.adaptive_equation.adapt_to_data(
                x_data, y_data, AdaptationDirection.BALANCE_BOTH
            )
            current_error = self.adaptive_equation.calculate_error(x_data, y_data)
            improvement = training_log[-1]['error'] - current_error
            
            training_log.append({
                'iteration': f'final_{i+1}',
                'phase': 'final_adaptation',
                'error': current_error,
                'improvement': improvement,
                'success': success
            })
            
            print(f"      ØªÙƒÙŠÙ Ù†Ù‡Ø§Ø¦ÙŠ {i+1}: Ø®Ø·Ø£ = {current_error:.6f}, ØªØ­Ø³Ù† = {improvement:.6f}")
            
            if not success:
                break
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ­Ø³Ù† Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
        final_error = self.adaptive_equation.calculate_error(x_data, y_data)
        total_improvement = initial_error - final_error
        improvement_percentage = (total_improvement / initial_error) * 100
        
        self.training_history = training_log
        
        print(f"\n   ğŸ‰ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨:")
        print(f"      Ø®Ø·Ø£ Ø£ÙˆÙ„ÙŠ: {initial_error:.6f}")
        print(f"      Ø®Ø·Ø£ Ù†Ù‡Ø§Ø¦ÙŠ: {final_error:.6f}")
        print(f"      ØªØ­Ø³Ù† Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {total_improvement:.6f} ({improvement_percentage:.2f}%)")
        
        return training_log
    
    def _apply_balanced_theories(self):
        """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«Ù„Ø§Ø« Ø¨ØªÙˆØ§Ø²Ù†"""
        
        # ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© Ø§Ù„ØªÙˆØ§Ø²Ù† Ø¨Ø­Ø°Ø±
        for component in self.adaptive_equation.components:
            if component['type'] == 'sigmoid':
                balance_factor = self.theories_integrator.zero_duality.calculate_balance_point(
                    abs(component['alpha']), 1.0
                )
                # ØªØ·Ø¨ÙŠÙ‚ Ø¬Ø²Ø¦ÙŠ Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ù…ÙØ±Ø·
                component['alpha'] *= (1.0 + 0.1 * (balance_factor - 1.0))
        
        # ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© Ø§Ù„ÙØªØ§Ø¦Ù„ Ø¨Ø­Ø°Ø±
        enhanced_components = self.theories_integrator.filament_connection.apply_filament_enhancement(
            self.adaptive_equation.components
        )
        
        # Ø¯Ù…Ø¬ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø¬Ø²Ø¦ÙŠ<|im_start|>
        for i, enhanced in enumerate(enhanced_components):
            if i < len(self.adaptive_equation.components):
                original = self.adaptive_equation.components[i]
                if enhanced['type'] == 'sigmoid':
                    # ØªØ·Ø¨ÙŠÙ‚ 30% Ù…Ù† Ø§Ù„ØªØ­Ø³ÙŠÙ† ÙÙ‚Ø·
                    alpha_improvement = enhanced['alpha'] - original['alpha']
                    original['alpha'] += 0.3 * alpha_improvement
    
    def comprehensive_evaluation(self, x_data, y_data):
        """ØªÙ‚ÙŠÙŠÙ… Ø´Ø§Ù…Ù„ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬"""
        
        print(f"\nğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø´Ø§Ù…Ù„ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù†...")
        
        if self.adaptive_equation is None:
            print("âŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¯Ø±Ø¨")
            return None
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        y_pred = self.adaptive_equation.evaluate(x_data)
        
        # ØªÙ‚ÙŠÙŠÙ… Ø¨Ø¹ØªØ¨Ø§Øª Ù…Ø®ØªÙ„ÙØ©
        thresholds = [0.2, 0.3, 0.4, 0.5]
        results = {}
        
        for threshold in thresholds:
            predictions = (y_pred > threshold).astype(int)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            accuracy = np.mean(predictions == y_data)
            true_positives = np.sum((predictions == 1) & (y_data == 1))
            predicted_positives = np.sum(predictions == 1)
            actual_positives = np.sum(y_data == 1)
            
            precision = true_positives / max(1, predicted_positives)
            recall = true_positives / max(1, actual_positives)
            f1_score = 2 * (precision * recall) / max(1e-10, precision + recall)
            
            results[threshold] = {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1_score,
                'true_positives': true_positives,
                'predicted_positives': predicted_positives
            }
            
            print(f"   Ø¹ØªØ¨Ø© {threshold}: Ø¯Ù‚Ø©={accuracy:.2%}, F1={f1_score:.2%}, Recall={recall:.2%}")
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ø¹ØªØ¨Ø©
        best_threshold = max(results.keys(), key=lambda t: results[t]['f1_score'])
        self.optimal_threshold = best_threshold
        
        print(f"\n   ğŸ† Ø£ÙØ¶Ù„ Ø¹ØªØ¨Ø©: {best_threshold} (F1-Score: {results[best_threshold]['f1_score']:.2%})")
        
        self.performance_metrics = results[best_threshold]
        self.performance_metrics['threshold'] = best_threshold
        self.performance_metrics['predictions'] = y_pred
        
        return results
    
    def predict_next_primes(self, known_primes, num_predictions=5):
        """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ©"""
        
        print(f"\nğŸ”® Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ©...")
        
        if self.adaptive_equation is None:
            print("âŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¯Ø±Ø¨")
            return []
        
        last_prime = known_primes[-1]
        print(f"   Ø¢Ø®Ø± Ø¹Ø¯Ø¯ Ø£ÙˆÙ„ÙŠ Ù…Ø¹Ø±ÙˆÙ: {last_prime}")
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„ØªØ§Ù„ÙŠ
        search_range = np.arange(last_prime + 1, last_prime + 100)
        predictions = self.adaptive_equation.evaluate(search_range)
        
        # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ†
        candidates = search_range[predictions > self.optimal_threshold]
        candidate_scores = predictions[predictions > self.optimal_threshold]
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø©
        sorted_indices = np.argsort(candidate_scores)[::-1]
        top_candidates = candidates[sorted_indices][:num_predictions]
        top_scores = candidate_scores[sorted_indices][:num_predictions]
        
        print(f"   ğŸ¯ Ø£ÙØ¶Ù„ {len(top_candidates)} Ù…Ø±Ø´Ø­ÙŠÙ†:")
        for i, (candidate, score) in enumerate(zip(top_candidates, top_scores), 1):
            print(f"      {i}. Ø§Ù„Ø¹Ø¯Ø¯ {candidate}: Ù†ØªÙŠØ¬Ø© = {score:.4f}")
        
        return top_candidates, top_scores
    
    def create_comprehensive_visualization(self, x_data, y_data, results):
        """Ø¥Ù†Ø´Ø§Ø¡ ØªØµÙˆØ± Ø´Ø§Ù…Ù„ Ù„Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©"""
        
        print(f"\nğŸ“ˆ Ø¥Ù†Ø´Ø§Ø¡ ØªØµÙˆØ± Ø´Ø§Ù…Ù„ Ù„Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©...")
        
        try:
            fig = plt.figure(figsize=(20, 15))
            fig.suptitle('Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ - Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø´Ø§Ù…Ù„Ø©', fontsize=20, fontweight='bold')
            
            # 1. Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ù…Ø¹ Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ù…Ø«Ù„Ù‰
            ax1 = plt.subplot(2, 3, 1)
            y_pred = self.performance_metrics['predictions']
            
            ax1.plot(x_data, y_pred, 'b-', label='ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬', linewidth=2)
            ax1.scatter(x_data[y_data == 1], [1]*np.sum(y_data), color='red', s=50, 
                       label='Ø£Ø¹Ø¯Ø§Ø¯ Ø£ÙˆÙ„ÙŠØ© Ø­Ù‚ÙŠÙ‚ÙŠØ©', zorder=5)
            ax1.axhline(y=self.optimal_threshold, color='green', linestyle='--', 
                       label=f'Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ù…Ø«Ù„Ù‰ ({self.optimal_threshold})', linewidth=2)
            ax1.set_title('Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ù…Ø¹ Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ù…Ø«Ù„Ù‰')
            ax1.set_xlabel('Ø§Ù„Ø¹Ø¯Ø¯')
            ax1.set_ylabel('Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© ÙƒÙˆÙ†Ù‡ Ø£ÙˆÙ„ÙŠ')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # 2. Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¹ØªØ¨Ø§Øª
            ax2 = plt.subplot(2, 3, 2)
            thresholds = list(results.keys())
            f1_scores = [results[t]['f1_score'] for t in thresholds]
            recalls = [results[t]['recall'] for t in thresholds]
            precisions = [results[t]['precision'] for t in thresholds]
            
            ax2.plot(thresholds, f1_scores, 'g-o', label='F1-Score', linewidth=2, markersize=8)
            ax2.plot(thresholds, recalls, 'b-s', label='Recall', linewidth=2, markersize=8)
            ax2.plot(thresholds, precisions, 'r-^', label='Precision', linewidth=2, markersize=8)
            ax2.axvline(x=self.optimal_threshold, color='purple', linestyle='--', alpha=0.7)
            ax2.set_title('Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¹ØªØ¨Ø§Øª')
            ax2.set_xlabel('Ø§Ù„Ø¹ØªØ¨Ø©')
            ax2.set_ylabel('Ø§Ù„Ù†ØªÙŠØ¬Ø©')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            # 3. ØªØ·ÙˆØ± Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            ax3 = plt.subplot(2, 3, 3)
            if self.training_history:
                iterations = []
                errors = []
                for i, entry in enumerate(self.training_history):
                    if isinstance(entry['iteration'], str):
                        iterations.append(i)
                    else:
                        iterations.append(entry['iteration'] - 1)
                    errors.append(entry['error'])
                
                ax3.plot(iterations, errors, 'purple', marker='o', linewidth=2, markersize=6)
                ax3.set_title('ØªØ·ÙˆØ± Ø§Ù„ØªØ¯Ø±ÙŠØ¨')
                ax3.set_xlabel('Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨')
                ax3.set_ylabel('Ø§Ù„Ø®Ø·Ø£')
                ax3.grid(True, alpha=0.3)
            
            # 4. ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
            ax4 = plt.subplot(2, 3, 4)
            ax4.hist(y_pred, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
            ax4.axvline(x=self.optimal_threshold, color='red', linestyle='--', 
                       label=f'Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ù…Ø«Ù„Ù‰ ({self.optimal_threshold})', linewidth=2)
            ax4.set_title('ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª')
            ax4.set_xlabel('Ù‚ÙŠÙ…Ø© Ø§Ù„ØªÙ†Ø¨Ø¤')
            ax4.set_ylabel('Ø§Ù„ØªÙƒØ±Ø§Ø±')
            ax4.legend()
            ax4.grid(True, alpha=0.3)
            
            # 5. Ù…ØµÙÙˆÙØ© Ø§Ù„Ø®Ù„Ø·
            ax5 = plt.subplot(2, 3, 5)
            predictions = (y_pred > self.optimal_threshold).astype(int)
            
            tp = np.sum((predictions == 1) & (y_data == 1))
            fp = np.sum((predictions == 1) & (y_data == 0))
            tn = np.sum((predictions == 0) & (y_data == 0))
            fn = np.sum((predictions == 0) & (y_data == 1))
            
            confusion_matrix = np.array([[tn, fp], [fn, tp]])
            im = ax5.imshow(confusion_matrix, interpolation='nearest', cmap='Blues')
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†ØµÙˆØµ
            for i in range(2):
                for j in range(2):
                    ax5.text(j, i, confusion_matrix[i, j], ha="center", va="center", 
                            color="white" if confusion_matrix[i, j] > confusion_matrix.max()/2 else "black",
                            fontsize=16, fontweight='bold')
            
            ax5.set_title('Ù…ØµÙÙˆÙØ© Ø§Ù„Ø®Ù„Ø·')
            ax5.set_xlabel('Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡')
            ax5.set_ylabel('Ø­Ù‚ÙŠÙ‚ÙŠ')
            ax5.set_xticks([0, 1])
            ax5.set_yticks([0, 1])
            ax5.set_xticklabels(['ØºÙŠØ± Ø£ÙˆÙ„ÙŠ', 'Ø£ÙˆÙ„ÙŠ'])
            ax5.set_yticklabels(['ØºÙŠØ± Ø£ÙˆÙ„ÙŠ', 'Ø£ÙˆÙ„ÙŠ'])
            
            # 6. Ù…Ù„Ø®Øµ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
            ax6 = plt.subplot(2, 3, 6)
            
            metrics = ['Ø§Ù„Ø¯Ù‚Ø©', 'Precision', 'Recall', 'F1-Score']
            values = [
                self.performance_metrics['accuracy'],
                self.performance_metrics['precision'],
                self.performance_metrics['recall'],
                self.performance_metrics['f1_score']
            ]
            
            colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']
            bars = ax6.bar(metrics, values, color=colors, alpha=0.8, edgecolor='black')
            
            # Ø¥Ø¶Ø§ÙØ© Ù‚ÙŠÙ… Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            for bar, value in zip(bars, values):
                height = bar.get_height()
                ax6.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                        f'{value:.2%}', ha='center', va='bottom', fontweight='bold', fontsize=12)
            
            ax6.set_title('Ù…Ù„Ø®Øµ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ')
            ax6.set_ylabel('Ø§Ù„Ù†ØªÙŠØ¬Ø©')
            ax6.set_ylim(0, 1)
            ax6.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù…
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f'final_enhanced_model_results_{timestamp}.png'
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            print(f"   âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØµÙˆØ± ÙÙŠ: {filename}")
            
            plt.show()
            
        except Exception as e:
            print(f"   âŒ ØªØ¹Ø°Ø± Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØµÙˆØ±: {e}")

def main():
    """ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"""
    
    print("ğŸš€ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…ØµØ­Ø­")
    print("Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙƒØ«Ø± ØªÙ‚Ø¯Ù…<|im_start|> Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª ÙˆØ§Ù„Ø¥ØµÙ„Ø§Ø­Ø§Øª")
    print("="*80)
    
    try:
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        final_model = FinalEnhancedGSEModel()
        
        # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©
        print(f"\nğŸ“Š ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©...")
        x_data, y_data, primes_list = generate_comprehensive_prime_data(120)
        
        print(f"   Ù†Ø·Ø§Ù‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: 2-120")
        print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…: {len(x_data)}")
        print(f"   Ø£Ø¹Ø¯Ø§Ø¯ Ø£ÙˆÙ„ÙŠØ©: {np.sum(y_data)}")
        print(f"   Ø¢Ø®Ø± 5 Ø£Ø¹Ø¯Ø§Ø¯ Ø£ÙˆÙ„ÙŠØ©: {primes_list[-5:]}")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù†
        final_model.create_optimized_model()
        
        # Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø°ÙƒÙŠ
        training_log = final_model.intelligent_training(x_data, y_data)
        
        # Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø´Ø§Ù…Ù„
        evaluation_results = final_model.comprehensive_evaluation(x_data, y_data)
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ§Ù„ÙŠØ©
        next_primes, scores = final_model.predict_next_primes(primes_list, num_predictions=5)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØµÙˆØ± Ø§Ù„Ø´Ø§Ù…Ù„
        final_model.create_comprehensive_visualization(x_data, y_data, evaluation_results)
        
        # Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        print("\n" + "="*80)
        print("ğŸ‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù†")
        print("="*80)
        
        best_metrics = final_model.performance_metrics
        print(f"\nğŸ† Ø£ÙØ¶Ù„ Ø£Ø¯Ø§Ø¡ Ù…Ø­Ù‚Ù‚:")
        print(f"   Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ù…Ø«Ù„Ù‰: {best_metrics['threshold']}")
        print(f"   Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ø¹Ø§Ù…Ø©: {best_metrics['accuracy']:.2%}")
        print(f"   Precision: {best_metrics['precision']:.2%}")
        print(f"   Recall: {best_metrics['recall']:.2%}")
        print(f"   F1-Score: {best_metrics['f1_score']:.2%}")
        print(f"   ØªÙ†Ø¨Ø¤Ø§Øª ØµØ­ÙŠØ­Ø©: {best_metrics['true_positives']}")
        print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§: {best_metrics['predicted_positives']}")
        
        print(f"\nğŸ”® Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ©:")
        for i, (prime, score) in enumerate(zip(next_primes, scores), 1):
            print(f"   {i}. Ø§Ù„Ø¹Ø¯Ø¯ {prime}: Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© {score:.4f}")
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        results_summary = {
            'timestamp': datetime.now().isoformat(),
            'model_type': 'final_enhanced_gse',
            'performance_metrics': {k: float(v) if isinstance(v, np.floating) else v 
                                  for k, v in best_metrics.items() if k != 'predictions'},
            'training_phases': len(training_log),
            'predicted_next_primes': next_primes.tolist() if len(next_primes) > 0 else [],
            'data_range': f"2-{max(x_data)}",
            'total_primes': int(np.sum(y_data))
        }
        
        with open('final_enhanced_results.json', 'w', encoding='utf-8') as f:
            json.dump(results_summary, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: final_enhanced_results.json")
        
        print(f"\nğŸŒŸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¬Ø§Ù‡Ø² ÙˆÙŠØ¹Ù…Ù„ Ø¨ÙƒÙØ§Ø¡Ø© Ø¹Ø§Ù„ÙŠØ©!")
        
    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
