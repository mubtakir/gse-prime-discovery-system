#!/usr/bin/env python3
"""
Ù…Ø¬Ù…ÙˆØ¹Ø© Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù„Ù…ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
Ø£Ø¯ÙˆØ§Øª Ù…ØªØ®ØµØµØ© Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ù†Ø¸Ø±ÙŠØ© Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ©
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from scipy.optimize import minimize
import pandas as pd
from datetime import datetime
import json
import sys
import os

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from advanced_hybrid_system import AdvancedHybridSystem
    from enhanced_matrix_sieve import enhanced_matrix_sieve
    print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¨Ø­Ø«")
except ImportError as e:
    print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª: {e}")
    sys.exit(1)

class PrimeResearchToolkit:
    """
    Ù…Ø¬Ù…ÙˆØ¹Ø© Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
    """
    
    def __init__(self):
        self.hybrid_system = AdvancedHybridSystem()
        self.research_data = {}
        self.hypotheses = []
        self.experiments = []
        
        print("ğŸ”¬ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù„Ù…ÙŠ")
    
    def prime_distribution_analysis(self, max_num=1000, intervals=10):
        """
        ØªØ­Ù„ÙŠÙ„ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
        """
        
        print(f"\nğŸ“Š ØªØ­Ù„ÙŠÙ„ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø­ØªÙ‰ {max_num}")
        print("="*60)
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
        primes = self._get_primes(max_num)
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Ø·Ø§Ù‚ Ø¥Ù„Ù‰ ÙØªØ±Ø§Øª
        interval_size = max_num // intervals
        interval_data = []
        
        for i in range(intervals):
            start = i * interval_size + 1
            end = (i + 1) * interval_size
            if i == intervals - 1:
                end = max_num
            
            primes_in_interval = [p for p in primes if start <= p <= end]
            density = len(primes_in_interval) / interval_size
            
            interval_data.append({
                'interval': f"{start}-{end}",
                'start': start,
                'end': end,
                'count': len(primes_in_interval),
                'density': density,
                'theoretical_density': 1 / np.log(end) if end > 1 else 0
            })
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª
        densities = [d['density'] for d in interval_data]
        theoretical = [d['theoretical_density'] for d in interval_data]
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·
        correlation = np.corrcoef(densities, theoretical)[0, 1]
        
        print(f"ğŸ“ˆ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
        print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©: {len(primes)}")
        print(f"   Ø§Ù„ÙƒØ«Ø§ÙØ© Ø§Ù„Ø¹Ø§Ù…Ø©: {len(primes)/max_num:.6f}")
        print(f"   Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ù…Ø¹ Ø§Ù„Ù†Ø¸Ø±ÙŠØ©: {correlation:.4f}")
        
        # Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙØªØ±Ø§Øª
        print(f"\nğŸ“Š ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙØªØ±Ø§Øª:")
        for data in interval_data:
            print(f"   {data['interval']}: {data['count']} Ø£Ø¹Ø¯Ø§Ø¯ØŒ ÙƒØ«Ø§ÙØ© = {data['density']:.6f}")
        
        return {
            'primes': primes,
            'interval_data': interval_data,
            'correlation': correlation,
            'total_primes': len(primes),
            'overall_density': len(primes)/max_num
        }
    
    def gap_analysis(self, max_num=1000):
        """
        ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¬ÙˆØ§Øª Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
        """
        
        print(f"\nğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¬ÙˆØ§Øª Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø­ØªÙ‰ {max_num}")
        print("="*60)
        
        primes = self._get_primes(max_num)
        
        if len(primes) < 2:
            print("âŒ Ø¹Ø¯Ø¯ ØºÙŠØ± ÙƒØ§ÙÙ Ù…Ù† Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„")
            return None
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙØ¬ÙˆØ§Øª
        gaps = [primes[i+1] - primes[i] for i in range(len(primes)-1)]
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙØ¬ÙˆØ§Øª
        try:
            mode_result = stats.mode(gaps, keepdims=True)
            mode_value = mode_result.mode[0] if len(mode_result.mode) > 0 else gaps[0] if gaps else 0
        except:
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù†ÙˆØ§Ù„ ÙŠØ¯ÙˆÙŠ<|im_start|>
            unique_gaps, gap_counts = np.unique(gaps, return_counts=True)
            mode_value = unique_gaps[np.argmax(gap_counts)] if len(unique_gaps) > 0 else 0

        gap_stats = {
            'mean': np.mean(gaps),
            'median': np.median(gaps),
            'std': np.std(gaps),
            'min': np.min(gaps),
            'max': np.max(gaps),
            'mode': mode_value
        }
        
        # ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¬ÙˆØ§Øª
        unique_gaps, gap_counts = np.unique(gaps, return_counts=True)
        gap_distribution = dict(zip(unique_gaps, gap_counts))
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
        even_gaps = [g for g in gaps if g % 2 == 0]
        odd_gaps = [g for g in gaps if g % 2 == 1]
        
        print(f"ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙØ¬ÙˆØ§Øª:")
        print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙØ¬ÙˆØ§Øª: {len(gaps)}")
        print(f"   Ù…ØªÙˆØ³Ø· Ø§Ù„ÙØ¬ÙˆØ©: {gap_stats['mean']:.2f}")
        print(f"   Ø§Ù„ÙˆØ³ÙŠØ·: {gap_stats['median']:.2f}")
        print(f"   Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ: {gap_stats['std']:.2f}")
        print(f"   Ø£ØµØºØ± ÙØ¬ÙˆØ©: {gap_stats['min']}")
        print(f"   Ø£ÙƒØ¨Ø± ÙØ¬ÙˆØ©: {gap_stats['max']}")
        print(f"   Ø§Ù„ÙØ¬ÙˆØ© Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹<|im_start|>: {gap_stats['mode']}")
        
        print(f"\nğŸ”¢ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·:")
        print(f"   ÙØ¬ÙˆØ§Øª Ø²ÙˆØ¬ÙŠØ©: {len(even_gaps)} ({len(even_gaps)/len(gaps)*100:.1f}%)")
        print(f"   ÙØ¬ÙˆØ§Øª ÙØ±Ø¯ÙŠØ©: {len(odd_gaps)} ({len(odd_gaps)/len(gaps)*100:.1f}%)")
        
        # Ø§Ù„ÙØ¬ÙˆØ§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹<|im_start|>
        print(f"\nğŸ“ˆ Ø£ÙƒØ«Ø± Ø§Ù„ÙØ¬ÙˆØ§Øª Ø´ÙŠÙˆØ¹<|im_start|>:")
        sorted_gaps = sorted(gap_distribution.items(), key=lambda x: x[1], reverse=True)
        for gap, count in sorted_gaps[:10]:
            percentage = count / len(gaps) * 100
            print(f"   ÙØ¬ÙˆØ© {gap}: {count} Ù…Ø±Ø© ({percentage:.1f}%)")
        
        return {
            'gaps': gaps,
            'statistics': gap_stats,
            'distribution': gap_distribution,
            'even_gaps': len(even_gaps),
            'odd_gaps': len(odd_gaps),
            'primes': primes
        }
    
    def twin_prime_analysis(self, max_num=1000):
        """
        ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø§Ù„ØªÙˆØ£Ù…
        """
        
        print(f"\nğŸ‘¥ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø§Ù„ØªÙˆØ£Ù… Ø­ØªÙ‰ {max_num}")
        print("="*60)
        
        primes = self._get_primes(max_num)
        
        # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø§Ù„ØªÙˆØ£Ù…
        twin_primes = []
        for i in range(len(primes)-1):
            if primes[i+1] - primes[i] == 2:
                twin_primes.append((primes[i], primes[i+1]))
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ²ÙŠØ¹
        twin_count = len(twin_primes)
        twin_density = twin_count / len(primes) if primes else 0
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª
        intervals = 10
        interval_size = max_num // intervals
        interval_twins = []
        
        for i in range(intervals):
            start = i * interval_size + 1
            end = (i + 1) * interval_size
            if i == intervals - 1:
                end = max_num
            
            twins_in_interval = [(p1, p2) for p1, p2 in twin_primes if start <= p1 <= end]
            interval_twins.append({
                'interval': f"{start}-{end}",
                'count': len(twins_in_interval),
                'density': len(twins_in_interval) / interval_size
            })
        
        print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªÙˆØ£Ù…:")
        print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©: {len(primes)}")
        print(f"   Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªÙˆØ£Ù…: {twin_count}")
        print(f"   Ù†Ø³Ø¨Ø© Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªÙˆØ£Ù…: {twin_density:.4f}")
        
        if twin_primes:
            print(f"\nğŸ‘¥ Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªÙˆØ£Ù…:")
            for i, (p1, p2) in enumerate(twin_primes[:10]):
                print(f"   {i+1:2d}. ({p1}, {p2})")
            
            if len(twin_primes) > 10:
                print(f"   ... Ùˆ {len(twin_primes)-10} Ø²ÙˆØ¬ Ø¢Ø®Ø±")
        
        print(f"\nğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªÙˆØ£Ù… Ø¹Ø¨Ø± Ø§Ù„ÙØªØ±Ø§Øª:")
        for data in interval_twins:
            print(f"   {data['interval']}: {data['count']} Ø£Ø²ÙˆØ§Ø¬")
        
        return {
            'twin_primes': twin_primes,
            'twin_count': twin_count,
            'twin_density': twin_density,
            'interval_analysis': interval_twins,
            'total_primes': len(primes)
        }
    
    def prime_patterns_discovery(self, max_num=500):
        """
        Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· ÙÙŠ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
        """
        
        print(f"\nğŸ” Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· ÙÙŠ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø­ØªÙ‰ {max_num}")
        print("="*60)
        
        primes = self._get_primes(max_num)
        
        patterns = {}
        
        # 1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø£Ø®ÙŠØ±Ø©
        last_digits = [p % 10 for p in primes if p > 10]
        last_digit_dist = {}
        for digit in last_digits:
            last_digit_dist[digit] = last_digit_dist.get(digit, 0) + 1
        
        patterns['last_digits'] = last_digit_dist
        
        # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø£ÙˆÙ„Ù‰
        first_digits = [int(str(p)[0]) for p in primes if p >= 10]
        first_digit_dist = {}
        for digit in first_digits:
            first_digit_dist[digit] = first_digit_dist.get(digit, 0) + 1
        
        patterns['first_digits'] = first_digit_dist
        
        # 3. ØªØ­Ù„ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
        digit_sums = [sum(int(d) for d in str(p)) for p in primes]
        digit_sum_dist = {}
        for s in digit_sums:
            digit_sum_dist[s] = digit_sum_dist.get(s, 0) + 1
        
        patterns['digit_sums'] = digit_sum_dist
        
        # 4. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø­Ø³Ø§Ø¨ÙŠØ©
        arithmetic_progressions = self._find_arithmetic_progressions(primes)
        patterns['arithmetic_progressions'] = arithmetic_progressions
        
        # 5. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ© (ØªÙ‚Ø±ÙŠØ¨ÙŠØ©)
        geometric_patterns = self._find_geometric_patterns(primes)
        patterns['geometric_patterns'] = geometric_patterns
        
        print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·:")
        
        print(f"\nğŸ”¢ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø£Ø®ÙŠØ±Ø©:")
        for digit, count in sorted(last_digit_dist.items()):
            percentage = count / len(last_digits) * 100
            print(f"   Ø§Ù„Ø±Ù‚Ù… {digit}: {count} Ù…Ø±Ø© ({percentage:.1f}%)")
        
        print(f"\nğŸ”¢ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø£ÙˆÙ„Ù‰:")
        for digit, count in sorted(first_digit_dist.items()):
            percentage = count / len(first_digits) * 100
            print(f"   Ø§Ù„Ø±Ù‚Ù… {digit}: {count} Ù…Ø±Ø© ({percentage:.1f}%)")
        
        print(f"\nâ• Ø£ÙƒØ«Ø± Ù…Ø¬Ø§Ù…ÙŠØ¹ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø´ÙŠÙˆØ¹<|im_start|>:")
        sorted_sums = sorted(digit_sum_dist.items(), key=lambda x: x[1], reverse=True)
        for s, count in sorted_sums[:10]:
            percentage = count / len(digit_sums) * 100
            print(f"   Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ {s}: {count} Ù…Ø±Ø© ({percentage:.1f}%)")
        
        if arithmetic_progressions:
            print(f"\nğŸ“ Ø§Ù„Ù…ØªØªØ§Ù„ÙŠØ§Øª Ø§Ù„Ø­Ø³Ø§Ø¨ÙŠØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
            for i, prog in enumerate(arithmetic_progressions[:5]):
                print(f"   {i+1}. {prog['sequence']} (ÙØ±Ù‚ = {prog['difference']})")
        
        return patterns
    
    def _find_arithmetic_progressions(self, primes, min_length=3):
        """
        Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØªØ§Ù„ÙŠØ§Øª Ø§Ù„Ø­Ø³Ø§Ø¨ÙŠØ© ÙÙŠ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
        """
        
        progressions = []
        
        for i in range(len(primes)):
            for j in range(i+1, len(primes)):
                diff = primes[j] - primes[i]
                sequence = [primes[i], primes[j]]
                
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…ØªØªØ§Ù„ÙŠØ©
                next_expected = primes[j] + diff
                for k in range(j+1, len(primes)):
                    if primes[k] == next_expected:
                        sequence.append(primes[k])
                        next_expected += diff
                    elif primes[k] > next_expected:
                        break
                
                if len(sequence) >= min_length:
                    progressions.append({
                        'sequence': sequence,
                        'difference': diff,
                        'length': len(sequence)
                    })
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª ÙˆØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ø·ÙˆÙ„
        unique_progressions = []
        seen = set()
        
        for prog in progressions:
            key = tuple(prog['sequence'])
            if key not in seen:
                seen.add(key)
                unique_progressions.append(prog)
        
        return sorted(unique_progressions, key=lambda x: x['length'], reverse=True)
    
    def _find_geometric_patterns(self, primes, tolerance=0.1):
        """
        Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ© Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠØ©
        """
        
        patterns = []
        
        for i in range(len(primes)-2):
            for j in range(i+1, len(primes)-1):
                for k in range(j+1, len(primes)):
                    p1, p2, p3 = primes[i], primes[j], primes[k]
                    
                    # ÙØ­Øµ Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ©
                    if p1 > 0 and p2 > 0:
                        ratio1 = p2 / p1
                        ratio2 = p3 / p2
                        
                        if abs(ratio1 - ratio2) / ratio1 < tolerance:
                            patterns.append({
                                'sequence': [p1, p2, p3],
                                'ratio': (ratio1 + ratio2) / 2,
                                'error': abs(ratio1 - ratio2) / ratio1
                            })
        
        return sorted(patterns, key=lambda x: x['error'])[:10]
    
    def _get_primes(self, max_num):
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
        """
        
        def is_prime(n):
            if n < 2:
                return False
            for i in range(2, int(n**0.5) + 1):
                if n % i == 0:
                    return False
            return True
        
        return [n for n in range(2, max_num + 1) if is_prime(n)]
    
    def generate_research_report(self, max_num=1000):
        """
        Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø¨Ø­Ø«ÙŠ Ø´Ø§Ù…Ù„
        """
        
        print(f"\nğŸ“‹ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø¨Ø­Ø«ÙŠ Ø´Ø§Ù…Ù„ Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø­ØªÙ‰ {max_num}")
        print("="*80)
        
        # ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
        distribution_analysis = self.prime_distribution_analysis(max_num)
        gap_analysis = self.gap_analysis(max_num)
        twin_analysis = self.twin_prime_analysis(max_num)
        pattern_analysis = self.prime_patterns_discovery(max_num)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        report = {
            'metadata': {
                'timestamp': datetime.now().isoformat(),
                'max_number': max_num,
                'analysis_type': 'comprehensive_prime_research'
            },
            'distribution_analysis': distribution_analysis,
            'gap_analysis': gap_analysis,
            'twin_prime_analysis': twin_analysis,
            'pattern_analysis': pattern_analysis
        }
        
        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        filename = f"prime_research_report_{max_num}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            # ØªØ­ÙˆÙŠÙ„ numpy arrays Ø¥Ù„Ù‰ lists Ù„Ù„Ø­ÙØ¸
            def convert_numpy(obj):
                if isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, (np.integer, np.int64, np.int32)):
                    return int(obj)
                elif isinstance(obj, (np.floating, np.float64, np.float32)):
                    return float(obj)
                elif isinstance(obj, dict):
                    return {str(k): convert_numpy(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_numpy(item) for item in obj]
                elif isinstance(obj, tuple):
                    return [convert_numpy(item) for item in obj]
                else:
                    return obj
            
            json.dump(convert_numpy(report), f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø¨Ø­Ø«ÙŠ ÙÙŠ: {filename}")
        
        return report

def main():
    """
    Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¨Ø­Ø«
    """
    
    print("ğŸ”¬ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù„Ù…ÙŠ ÙÙŠ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©")
    print("Ø£Ø¯ÙˆØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠ")
    print("="*80)
    
    try:
        toolkit = PrimeResearchToolkit()
        
        # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø¨Ø­Ø«ÙŠ Ø´Ø§Ù…Ù„
        report = toolkit.generate_research_report(500)
        
        print(f"\nğŸ‰ ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ø­Ø«ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„!")
        print(f"ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø­ÙÙˆØ¸Ø© ÙˆÙ…ØªØ§Ø­Ø© Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø¹Ù„Ù…ÙŠØ©")
        
    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø£ ÙÙŠ Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¨Ø­Ø«: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
