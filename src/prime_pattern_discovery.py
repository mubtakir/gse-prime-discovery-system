"""
Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· ÙˆØ§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
Prime Pattern Discovery - New Laws and Conjectures
"""

import numpy as np
import matplotlib.pyplot as plt
import time
import sys
import os
from scipy import stats
from scipy.optimize import curve_fit

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± Ø§Ù„Ù…ØµØ¯Ø±
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from gse_advanced_model import AdvancedGSEModel
from optimizer_advanced import GSEOptimizer
from target_functions import TargetFunctions
from number_theory_utils import NumberTheoryUtils

class PrimePatternDiscovery:
    """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· ÙˆØ§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©"""
    
    def __init__(self):
        self.primes = []
        self.prime_gaps = []
        self.prime_densities = []
        self.discovered_patterns = {}
        self.conjectures = []
        self.experiment_log = []
    
    def log_message(self, message):
        """ØªØ³Ø¬ÙŠÙ„ Ø±Ø³Ø§Ù„Ø© Ù…Ø¹ Ø§Ù„ÙˆÙ‚Øª"""
        timestamp = time.strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        print(log_entry)
        self.experiment_log.append(log_entry)
    
    def analyze_prime_distribution_patterns(self, max_n=2000):
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©"""
        
        self.log_message("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©...")
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
        self.primes = NumberTheoryUtils.generate_primes(max_n)
        self.log_message(f"   ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(self.primes)} Ø¹Ø¯Ø¯ Ø£ÙˆÙ„ÙŠ Ø­ØªÙ‰ {max_n}")
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙØ¬ÙˆØ§Øª
        self.prime_gaps = [self.primes[i+1] - self.primes[i] for i in range(len(self.primes)-1)]
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙƒØ«Ø§ÙØ§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©
        window_size = 100
        self.prime_densities = []
        
        for i in range(window_size, max_n, window_size):
            primes_in_window = len([p for p in self.primes if i-window_size < p <= i])
            density = primes_in_window / window_size
            self.prime_densities.append((i, density))
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
        patterns = {
            'gap_analysis': self.analyze_gap_patterns(),
            'density_analysis': self.analyze_density_patterns(),
            'modular_analysis': self.analyze_modular_patterns(),
            'clustering_analysis': self.analyze_clustering_patterns(),
            'spiral_analysis': self.analyze_spiral_patterns()
        }
        
        self.discovered_patterns = patterns
        return patterns
    
    def analyze_gap_patterns(self):
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· ÙØ¬ÙˆØ§Øª Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©"""
        
        self.log_message("   ğŸ“ ØªØ­Ù„ÙŠÙ„ ÙØ¬ÙˆØ§Øª Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©...")
        
        gaps = np.array(self.prime_gaps)
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø£Ø³Ø§Ø³ÙŠØ©
        gap_stats = {
            'mean': np.mean(gaps),
            'std': np.std(gaps),
            'max': np.max(gaps),
            'min': np.min(gaps),
            'median': np.median(gaps)
        }
        
        # ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¬ÙˆØ§Øª
        unique_gaps, gap_counts = np.unique(gaps, return_counts=True)
        gap_distribution = dict(zip(unique_gaps, gap_counts))
        
        # Ø§Ù„ÙØ¬ÙˆØ§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹
        most_common_gaps = sorted(gap_distribution.items(), key=lambda x: x[1], reverse=True)[:10]
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… Ù„Ù„ÙØ¬ÙˆØ§Øª
        x_positions = np.arange(len(gaps))
        slope, intercept, r_value, p_value, std_err = stats.linregress(x_positions, gaps)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ø¯ÙˆØ±ÙŠØ© ÙÙŠ Ø§Ù„ÙØ¬ÙˆØ§Øª
        gap_autocorr = np.correlate(gaps, gaps, mode='full')
        gap_autocorr = gap_autocorr[gap_autocorr.size // 2:]
        
        return {
            'statistics': gap_stats,
            'distribution': gap_distribution,
            'most_common': most_common_gaps,
            'trend': {
                'slope': slope,
                'r_squared': r_value**2,
                'p_value': p_value
            },
            'autocorrelation': gap_autocorr[:100].tolist()  # Ø£ÙˆÙ„ 100 Ù‚ÙŠÙ…Ø©
        }
    
    def analyze_density_patterns(self):
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· ÙƒØ«Ø§ÙØ© Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©"""
        
        self.log_message("   ğŸ“Š ØªØ­Ù„ÙŠÙ„ ÙƒØ«Ø§ÙØ© Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©...")
        
        positions = [d[0] for d in self.prime_densities]
        densities = [d[1] for d in self.prime_densities]
        
        # Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„Ù†Ø¸Ø±ÙŠØ© (1/ln(x))
        theoretical_densities = [1/np.log(x) if x > 1 else 0 for x in positions]
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø¹Ù† Ø§Ù„Ù†Ø¸Ø±ÙŠØ©
        deviations = [abs(d - t) for d, t in zip(densities, theoretical_densities)]
        avg_deviation = np.mean(deviations)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ø¯ÙˆØ±ÙŠØ© ÙÙŠ Ø§Ù„ÙƒØ«Ø§ÙØ©
        density_fft = np.fft.fft(densities)
        dominant_frequencies = np.argsort(np.abs(density_fft))[-5:]
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡
        slope, intercept, r_value, p_value, std_err = stats.linregress(positions, densities)
        
        return {
            'positions': positions,
            'densities': densities,
            'theoretical_densities': theoretical_densities,
            'average_deviation': avg_deviation,
            'trend': {
                'slope': slope,
                'r_squared': r_value**2
            },
            'dominant_frequencies': dominant_frequencies.tolist(),
            'fft_magnitudes': np.abs(density_fft).tolist()
        }
    
    def analyze_modular_patterns(self):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ© (modular patterns)"""
        
        self.log_message("   ğŸ”¢ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ©...")
        
        modular_patterns = {}
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© modulo Ø£Ø¹Ø¯Ø§Ø¯ Ù…Ø®ØªÙ„ÙØ©
        for mod in [6, 10, 12, 30, 60]:
            residues = [p % mod for p in self.primes if p > mod]
            unique_residues, counts = np.unique(residues, return_counts=True)
            
            modular_patterns[f'mod_{mod}'] = {
                'residues': unique_residues.tolist(),
                'counts': counts.tolist(),
                'distribution': dict(zip(unique_residues, counts))
            }
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ø®Ø§ØµØ©
        # Ù†Ù…Ø· 6nÂ±1
        mod6_pattern = modular_patterns['mod_6']
        mod6_analysis = {
            'pattern_6n_plus_1': mod6_pattern['distribution'].get(1, 0),
            'pattern_6n_minus_1': mod6_pattern['distribution'].get(5, 0),
            'other_residues': sum(mod6_pattern['counts']) - mod6_pattern['distribution'].get(1, 0) - mod6_pattern['distribution'].get(5, 0)
        }
        
        return {
            'modular_distributions': modular_patterns,
            'mod6_analysis': mod6_analysis
        }
    
    def analyze_clustering_patterns(self):
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªØ¬Ù…Ø¹ ÙÙŠ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©"""
        
        self.log_message("   ğŸ¯ ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªØ¬Ù…Ø¹...")
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø§Ù„ØªÙˆØ£Ù…
        twin_primes = []
        for i in range(len(self.primes)-1):
            if self.primes[i+1] - self.primes[i] == 2:
                twin_primes.append((self.primes[i], self.primes[i+1]))
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø§Ù„Ø«Ù„Ø§Ø«ÙŠØ©
        triplet_primes = []
        for i in range(len(self.primes)-2):
            if (self.primes[i+1] - self.primes[i] == 2 and 
                self.primes[i+2] - self.primes[i+1] == 4) or \
               (self.primes[i+1] - self.primes[i] == 4 and 
                self.primes[i+2] - self.primes[i+1] == 2):
                triplet_primes.append((self.primes[i], self.primes[i+1], self.primes[i+2]))
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø¨ÙŠÙ† Ø§Ù„ØªØ¬Ù…Ø¹Ø§Øª
        twin_positions = [tp[0] for tp in twin_primes]
        if len(twin_positions) > 1:
            twin_gaps = [twin_positions[i+1] - twin_positions[i] for i in range(len(twin_positions)-1)]
            avg_twin_gap = np.mean(twin_gaps)
        else:
            twin_gaps = []
            avg_twin_gap = 0
        
        return {
            'twin_primes': twin_primes[:20],  # Ø£ÙˆÙ„ 20 Ø²ÙˆØ¬
            'twin_count': len(twin_primes),
            'triplet_primes': triplet_primes[:10],  # Ø£ÙˆÙ„ 10 Ø«Ù„Ø§Ø«ÙŠØ§Øª
            'triplet_count': len(triplet_primes),
            'twin_gaps': twin_gaps[:50],  # Ø£ÙˆÙ„ 50 ÙØ¬ÙˆØ©
            'average_twin_gap': avg_twin_gap
        }
    
    def analyze_spiral_patterns(self):
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø­Ù„Ø²ÙˆÙ† (Ulam Spiral)"""
        
        self.log_message("   ğŸŒ€ ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø­Ù„Ø²ÙˆÙ†...")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø­Ù„Ø²ÙˆÙ† Ø£ÙˆÙ„Ø§Ù…
        size = 50  # Ø­Ø¬Ù… Ø§Ù„Ø´Ø¨ÙƒØ©
        spiral = np.zeros((size, size))
        
        # Ù…Ù„Ø¡ Ø§Ù„Ø­Ù„Ø²ÙˆÙ†
        x, y = size // 2, size // 2
        spiral[x, y] = 1
        
        directions = [(0, 1), (-1, 0), (0, -1), (1, 0)]  # ÙŠÙ…ÙŠÙ†ØŒ Ø£Ø¹Ù„Ù‰ØŒ ÙŠØ³Ø§Ø±ØŒ Ø£Ø³ÙÙ„
        direction = 0
        steps = 1
        num = 2
        
        while num <= size * size:
            for _ in range(2):  # ÙƒÙ„ Ø§ØªØ¬Ø§Ù‡ ÙŠØªÙƒØ±Ø± Ù…Ø±ØªÙŠÙ†
                for _ in range(steps):
                    if num > size * size:
                        break
                    dx, dy = directions[direction]
                    x, y = x + dx, y + dy
                    if 0 <= x < size and 0 <= y < size:
                        spiral[x, y] = num
                        num += 1
                direction = (direction + 1) % 4
                if num > size * size:
                    break
            steps += 1
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© ÙÙŠ Ø§Ù„Ø­Ù„Ø²ÙˆÙ†
        prime_positions = []
        for i in range(size):
            for j in range(size):
                if spiral[i, j] > 0 and NumberTheoryUtils.is_prime(int(spiral[i, j])):
                    prime_positions.append((i, j, int(spiral[i, j])))
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø®Ø·ÙŠØ©
        diagonal_primes = []
        for i in range(size):
            # Ø§Ù„Ù‚Ø·Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
            if spiral[i, i] > 0 and NumberTheoryUtils.is_prime(int(spiral[i, i])):
                diagonal_primes.append(int(spiral[i, i]))
            # Ø§Ù„Ù‚Ø·Ø± Ø§Ù„Ø«Ø§Ù†ÙˆÙŠ
            if spiral[i, size-1-i] > 0 and NumberTheoryUtils.is_prime(int(spiral[i, size-1-i])):
                diagonal_primes.append(int(spiral[i, size-1-i]))
        
        return {
            'spiral_size': size,
            'total_primes_in_spiral': len(prime_positions),
            'prime_positions': prime_positions[:50],  # Ø£ÙˆÙ„ 50 Ù…ÙˆÙ‚Ø¹
            'diagonal_primes': diagonal_primes,
            'prime_density_in_spiral': len(prime_positions) / (size * size)
        }
    
    def discover_new_conjectures(self):
        """Ø§ÙƒØªØ´Ø§Ù ÙØ±Ø¶ÙŠØ§Øª Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙƒØªØ´ÙØ©"""
        
        self.log_message("ğŸ”¬ Ø§ÙƒØªØ´Ø§Ù ÙØ±Ø¶ÙŠØ§Øª Ø¬Ø¯ÙŠØ¯Ø©...")
        
        conjectures = []
        
        # ÙØ±Ø¶ÙŠØ© 1: Ù†Ù…Ø· Ø§Ù„ÙØ¬ÙˆØ§Øª Ø§Ù„Ù…ØªØ²Ø§ÙŠØ¯Ø©
        gap_analysis = self.discovered_patterns['gap_analysis']
        if gap_analysis['trend']['slope'] > 0:
            conjecture1 = {
                'name': 'ÙØ±Ø¶ÙŠØ© Ø§Ù„ÙØ¬ÙˆØ§Øª Ø§Ù„Ù…ØªØ²Ø§ÙŠØ¯Ø© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©',
                'statement': f'Ù…ØªÙˆØ³Ø· ÙØ¬ÙˆØ§Øª Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© ÙŠØ²ÙŠØ¯ Ø¨Ù…Ø¹Ø¯Ù„ {gap_analysis["trend"]["slope"]:.6f} Ù„ÙƒÙ„ Ø¹Ø¯Ø¯ Ø£ÙˆÙ„ÙŠ',
                'confidence': gap_analysis['trend']['r_squared'],
                'evidence': f'RÂ² = {gap_analysis["trend"]["r_squared"]:.4f}'
            }
            conjectures.append(conjecture1)
        
        # ÙØ±Ø¶ÙŠØ© 2: Ù†Ù…Ø· Ø§Ù„ÙƒØ«Ø§ÙØ© Ø§Ù„Ù…Ø­Ø³Ù†
        density_analysis = self.discovered_patterns['density_analysis']
        if density_analysis['average_deviation'] < 0.01:
            conjecture2 = {
                'name': 'ÙØ±Ø¶ÙŠØ© Ø§Ù„ÙƒØ«Ø§ÙØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø©',
                'statement': f'ÙƒØ«Ø§ÙØ© Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© ØªØªØ¨Ø¹ Ù†Ù…Ø· 1/ln(x) Ù…Ø¹ Ø§Ù†Ø­Ø±Ø§Ù Ù…ØªÙˆØ³Ø· {density_analysis["average_deviation"]:.6f}',
                'confidence': 1 - density_analysis['average_deviation'],
                'evidence': f'Ù…ØªÙˆØ³Ø· Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù = {density_analysis["average_deviation"]:.6f}'
            }
            conjectures.append(conjecture2)
        
        # ÙØ±Ø¶ÙŠØ© 3: Ù†Ù…Ø· Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø§Ù„ØªÙˆØ£Ù…
        clustering_analysis = self.discovered_patterns['clustering_analysis']
        if clustering_analysis['twin_count'] > 0:
            twin_density = clustering_analysis['twin_count'] / len(self.primes)
            conjecture3 = {
                'name': 'ÙØ±Ø¶ÙŠØ© ÙƒØ«Ø§ÙØ© Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø§Ù„ØªÙˆØ£Ù…',
                'statement': f'Ù†Ø³Ø¨Ø© Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø§Ù„ØªÙˆØ£Ù… ØªÙ‚Ø§Ø±Ø¨ {twin_density:.4f} Ù…Ù† Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©',
                'confidence': 0.8,  # Ø«Ù‚Ø© Ù…ØªÙˆØ³Ø·Ø©
                'evidence': f'{clustering_analysis["twin_count"]} Ø²ÙˆØ¬ ØªÙˆØ£Ù… Ù…Ù† Ø£ØµÙ„ {len(self.primes)} Ø¹Ø¯Ø¯ Ø£ÙˆÙ„ÙŠ'
            }
            conjectures.append(conjecture3)
        
        # ÙØ±Ø¶ÙŠØ© 4: Ù†Ù…Ø· Ù…Ø¹ÙŠØ§Ø±ÙŠ Ø¬Ø¯ÙŠØ¯
        modular_analysis = self.discovered_patterns['modular_analysis']
        mod6_analysis = modular_analysis['mod6_analysis']
        total_mod6 = mod6_analysis['pattern_6n_plus_1'] + mod6_analysis['pattern_6n_minus_1']
        if total_mod6 > 0:
            ratio_6n_plus_1 = mod6_analysis['pattern_6n_plus_1'] / total_mod6
            conjecture4 = {
                'name': 'ÙØ±Ø¶ÙŠØ© Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ 6nÂ±1',
                'statement': f'Ù…Ù† Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø§Ù„ÙƒØ¨ÙŠØ±Ø©ØŒ {ratio_6n_plus_1:.2%} ØªØ£ØªÙŠ ÙÙŠ Ø´ÙƒÙ„ 6n+1 ÙˆØ§Ù„Ø¨Ø§Ù‚ÙŠ 6n-1',
                'confidence': 0.9,
                'evidence': f'{mod6_analysis["pattern_6n_plus_1"]} Ø¹Ø¯Ø¯ 6n+1 Ùˆ {mod6_analysis["pattern_6n_minus_1"]} Ø¹Ø¯Ø¯ 6n-1'
            }
            conjectures.append(conjecture4)
        
        # ÙØ±Ø¶ÙŠØ© 5: Ù†Ù…Ø· Ø§Ù„Ø­Ù„Ø²ÙˆÙ†
        spiral_analysis = self.discovered_patterns['spiral_analysis']
        spiral_density = spiral_analysis['prime_density_in_spiral']
        conjecture5 = {
            'name': 'ÙØ±Ø¶ÙŠØ© ÙƒØ«Ø§ÙØ© Ø­Ù„Ø²ÙˆÙ† Ø£ÙˆÙ„Ø§Ù…',
            'statement': f'ÙƒØ«Ø§ÙØ© Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© ÙÙŠ Ø­Ù„Ø²ÙˆÙ† Ø£ÙˆÙ„Ø§Ù… ØªÙ‚Ø§Ø±Ø¨ {spiral_density:.4f}',
            'confidence': 0.7,
            'evidence': f'{spiral_analysis["total_primes_in_spiral"]} Ø¹Ø¯Ø¯ Ø£ÙˆÙ„ÙŠ ÙÙŠ Ø´Ø¨ÙƒØ© {spiral_analysis["spiral_size"]}Ã—{spiral_analysis["spiral_size"]}'
        }
        conjectures.append(conjecture5)
        
        self.conjectures = conjectures
        return conjectures
    
    def formulate_gse_prime_law(self):
        """ØµÙŠØ§ØºØ© Ù‚Ø§Ù†ÙˆÙ† GSE Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©"""
        
        self.log_message("âš–ï¸ ØµÙŠØ§ØºØ© Ù‚Ø§Ù†ÙˆÙ† GSE Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©...")
        
        # ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ GSE Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©
        x_data = np.array(range(2, len(self.primes) + 2))
        y_data = np.array(self.primes)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ GSE Ù…ØªÙ‚Ø¯Ù…
        gse_model = AdvancedGSEModel()
        gse_model.add_sigmoid(alpha=complex(1.0, 0.1), n=2.0, z=complex(1.0, 0.0), x0=10.0)
        gse_model.add_sigmoid(alpha=complex(0.8, -0.1), n=1.8, z=complex(0.9, 0.1), x0=50.0)
        gse_model.add_sigmoid(alpha=complex(0.6, 0.2), n=1.5, z=complex(1.1, -0.1), x0=100.0)
        
        # Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        optimizer = GSEOptimizer(gse_model)
        result = optimizer.optimize_differential_evolution(x_data, y_data, max_iter=200, verbose=False)
        
        # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        y_pred = gse_model.evaluate(x_data)
        r2 = 1 - (np.sum((y_data - y_pred) ** 2) / np.sum((y_data - np.mean(y_data)) ** 2))
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
        components = []
        for i, comp in enumerate(gse_model.sigmoid_components):
            components.append({
                'component': i + 1,
                'alpha': comp['alpha'],
                'n': comp['n'],
                'z': comp['z'],
                'x0': comp['x0']
            })
        
        # ØµÙŠØ§ØºØ© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†
        gse_law = {
            'name': 'Ù‚Ø§Ù†ÙˆÙ† GSE Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©',
            'formula': 'P(n) = Î£[Î±áµ¢ * (1 + e^(-náµ¢*(x-xâ‚€áµ¢)*záµ¢))^(-1)]',
            'components': components,
            'accuracy': r2,
            'domain': f'n âˆˆ [1, {len(self.primes)}]',
            'description': 'Ù‚Ø§Ù†ÙˆÙ† Ø±ÙŠØ§Ø¶ÙŠ ÙŠØµÙ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠ Ø±Ù‚Ù… n Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¬Ù…ÙˆØ¹ Ø¯ÙˆØ§Ù„ Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ Ù…Ø¹Ù‚Ø¯Ø©'
        }
        
        return gse_law
    
    def generate_comprehensive_report(self):
        """Ø¥Ù†ØªØ§Ø¬ ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„ Ù„Ù„Ø§ÙƒØªØ´Ø§ÙØ§Øª"""
        
        report = []
        report.append("=" * 80)
        report.append("ØªÙ‚Ø±ÙŠØ± Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· ÙˆØ§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©")
        report.append("=" * 80)
        
        # Ù…Ù„Ø®Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        report.append(f"\nğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
        report.append(f"   Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø§Ù„Ù…Ø­Ù„Ù„Ø©: {len(self.primes)}")
        report.append(f"   Ø£ÙƒØ¨Ø± Ø¹Ø¯Ø¯ Ø£ÙˆÙ„ÙŠ: {max(self.primes) if self.primes else 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'}")
        report.append(f"   Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¬ÙˆØ§Øª Ø§Ù„Ù…Ø­Ù„Ù„Ø©: {len(self.prime_gaps)}")
        
        # Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙƒØªØ´ÙØ©
        if 'gap_analysis' in self.discovered_patterns:
            gap_stats = self.discovered_patterns['gap_analysis']['statistics']
            report.append(f"\nğŸ“ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¬ÙˆØ§Øª:")
            report.append(f"   Ù…ØªÙˆØ³Ø· Ø§Ù„ÙØ¬ÙˆØ©: {gap_stats['mean']:.2f}")
            report.append(f"   Ø£ÙƒØ¨Ø± ÙØ¬ÙˆØ©: {gap_stats['max']}")
            report.append(f"   Ø£ØµØºØ± ÙØ¬ÙˆØ©: {gap_stats['min']}")
        
        # Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©
        if self.conjectures:
            report.append(f"\nğŸ”¬ Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
            for i, conjecture in enumerate(self.conjectures, 1):
                report.append(f"   {i}. {conjecture['name']}")
                report.append(f"      Ø§Ù„Ø¨ÙŠØ§Ù†: {conjecture['statement']}")
                report.append(f"      Ø§Ù„Ø«Ù‚Ø©: {conjecture['confidence']:.2%}")
                report.append(f"      Ø§Ù„Ø¯Ù„ÙŠÙ„: {conjecture['evidence']}")
                report.append("")
        
        report.append("=" * 80)
        
        return "\n".join(report)
    
    def run_complete_discovery(self, max_n=2000):
        """ØªØ´ØºÙŠÙ„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙƒØ§Ù…Ù„Ø©"""
        
        self.log_message("ğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø´Ø§Ù…Ù„Ø©")
        self.log_message("=" * 60)
        
        # 1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
        patterns = self.analyze_prime_distribution_patterns(max_n)
        
        # 2. Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª
        conjectures = self.discover_new_conjectures()
        
        # 3. ØµÙŠØ§ØºØ© Ù‚Ø§Ù†ÙˆÙ† GSE
        gse_law = self.formulate_gse_prime_law()
        
        # 4. Ø¥Ù†ØªØ§Ø¬ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        report = self.generate_comprehensive_report()
        
        self.log_message("\n" + "=" * 60)
        self.log_message("ğŸ‰ Ø§Ù†ØªÙ‡Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§ÙƒØªØ´Ø§Ù!")
        
        return {
            'patterns': patterns,
            'conjectures': conjectures,
            'gse_law': gse_law,
            'report': report
        }

def main():
    """ØªØ´ØºÙŠÙ„ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·"""
    
    discovery = PrimePatternDiscovery()
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙƒØ§Ù…Ù„
    results = discovery.run_complete_discovery(max_n=3000)
    
    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    print("\n" + results['report'])
    
    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª
    print("\nğŸ”¬ Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
    for conjecture in results['conjectures']:
        print(f"\nğŸ“‹ {conjecture['name']}")
        print(f"   {conjecture['statement']}")
        print(f"   Ø§Ù„Ø«Ù‚Ø©: {conjecture['confidence']:.2%}")
    
    # Ø·Ø¨Ø§Ø¹Ø© Ù‚Ø§Ù†ÙˆÙ† GSE
    print(f"\nâš–ï¸ {results['gse_law']['name']}")
    print(f"   Ø§Ù„ØµÙŠØºØ©: {results['gse_law']['formula']}")
    print(f"   Ø§Ù„Ø¯Ù‚Ø©: {results['gse_law']['accuracy']:.4f}")
    
    return discovery, results

if __name__ == "__main__":
    discovery, results = main()
